# **Custom Resources**

The `rating-operator` uses *CustomResources* for most of its configuration need.
It also emits one to notify other applications of the availability of data.
We describe in this document every aspect of each resources we use, with usable examples.

## ***ratings**.charts.helm.k8s.io*

This resource describes a rating instance, and is used by the operator to deploy the needed stack.
It holds application specific parameters, such as image versions, resource limitations, or Prometheus instance location.
An example of such object can be found [here](/deploy/crds/charts.helm.k8s.io_v1alpha1_rating_cr.yaml) and is documented in [there](/documentation/CONFIGURE.md).

The operator watch this resource and react to change to adapt the instance accordingly.
Multiple `Rating` stacks can be deployed in the same cluster, but only one rating instance is allowed per namespace.
The operator can, from its namespace, handle multiple `Rating` objects, and deploy them in their respective location.

You can experiment with your `Rating` configuration by running:

```sh
$ kubectl edit ratings.charts.helm.k8s.io rating
# Do some changes, changing port numbers for example
[...]
rating.charts.helm.k8s.io/rating edited
```

Once the changes are accepted, you will see the operator reconfiguring the rating stack with the new parameters.

## ***ratingrules**.rating.alterway.fr*

This custom resource serves multiple purposes:

- Describing the `Metrics` list considered by this set of rules (Only for metering based rating, which is deprecated)
- Describing the `Rules` used by the operator to rate metrics

`RatingRules` are used depending on the validation timestamp they hold, to enable configuration versionning. (Only for metering based rating)
More info on the subject [here](/documentation/FEATURES.md)

Consider this minimal example:

```yml
---
apiVersion: rating.alterway.fr/v1
kind: RatingRule
metadata:
  name: example-rules
spec:
  metrics:
    request_cpu:
      report_name: pod-rating-cpu-request-hourly
      presto_table: report_metering_pod_rating_cpu_request_hourly
      presto_column: pod_request_cpu_core_seconds
      unit: core-seconds
  rules:
  -
    name: rules_example
    labelSet:
        foo: bar
    rules:
    -
        metric: request_cpu
        value: 0.00075
        unit: core-hours
  -
    name: rules_default
    rules:
    -
      metric: request_cpu
      value: 0.5
      unit: core-hours
```

The `metrics` part of this configuration is used only by the metering based rating (DEPRECATED) and is meant to be removed.
If you do not intend to use this version of the rating, please skip to the next point.

This configuration is used by the rating to get data from **metering-operator** database, presto.
It contains 5 points:

- The top key is the **name of the metric** in the database (here, **request_cpu**). It will also be used to match a rule in the `Rules` category.
- **report_name** is the name of the `Reports` object generated by metering-operator. A list of available reports can be obtained by using
  
```sh
$ kubectl -n $METERING_NAMESPACE get reports.metering.openshift.io
NAME                               QUERY                       SCHEDULE   RUNNING                  FAILED   LAST REPORT TIME       AGE
pod-rating-cpu-request-hourly      pod-rating-cpu-request      hourly     ReportingPeriodWaiting            2020-07-30T09:00:00Z   7d18h
[...]
```

- **presto_table** is the name of the table in the Presto database. It holds the aggregated data generated by metering-operator
- **presto_column** correspond to the "value" key in most databases, but changes for every reports in presto.
- **unit** will be matched with the **unit** key in `rules` defininition to apply the proper time conversion (millicore/seconds to hours for this example, GiB-hours is the other possibility).

You can have an unlimited number of metrics defined per `RatingRule`, but a metric will not be rated if it have no matches in the `rules` category.

----

The `rules` key correspond to a set of values to use in the transformation to a given metric.
It is used by both rating mechanism, with some differences that are detailled [here](/documentation/FEATURES.md).

`Rules` are described as an *ordered list* to enable pattern matching, via the **labelSet** key.

In our example, if a data frame have a {'foo': 'bar'} label and its metric is *request_cpu*, it will be rated by the **rules_example** ruleset.
On the other hand, if the match doesn't succeed, then the operator will keep trying to match successive ruleset until:

- It finds an appropriate ruleset to match labels with
- It finds a ruleset that doesn't require labels matching and have a rule for its metric, in our case **rules_default**.
- It doesn't find anything, thus not rating the frame

The most recent `RatingRule` is exposed to Prometheus, making all the values and labelset available for query building with promQL (in RatedMetrics, for example)
You can expect to find each **labelSet** with their respective value plus the value of default ruleset as metric in Prometheus.
```sh
usage_cpu{[...]}
usage_cpu{[...], foo="bar"}
```

To get a list of the metrics exposed to Prometheus, query the `/rules_metrics` endpoint of the **rating-operator-api**.

```sh
$ curl http://rating-api.rating:80/rules_metrics
request_cpu 1
usage_cpu 1
request_memory 1
usage_memory 1
# EOF
```

## ***reactiverules**.rating.alterway.fr*

A `ReactiveRule` describe the configuration of a metric to be rated.
Let's consider this example:

```yml
apiVersion: rating.alterway.fr/v1
kind: ReactiveRule
metadata:
  name: reactive-rule-test-metric
spec:
  metric: (sum(rate(container_memory_usage_bytes[2h])) BY (pod, namespace) + on (pod,
    namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""})
    by (pod, namespace, node) * 0)) * on () group_left() usage_memory
  name: test_metric
  timeframe: 10s
```

Three keys have to be defined in a `ReactiveRule`:

- **metric** defines what to query from Prometheus. Every valid PromQL expression can be used here.
- **name** is the future name of the metric
- **timeframe** correspond to the time between every data processing run. It also defines the precision of your metric. Only values in seconds are accepted, as shown above. In case of wrong format, base value is used (60s)

As soon as this resource is created, the rating will pick it up and start processing frames.

**Hint** Before lowering the **timeframe** parameter too much, make sure your storage capatibilities can handle it (Depending of the metric, it can produce big storage imprint quite quickly). There's no mechanism yet to rotate the data in the database, and multiple, low timeframes `ReactiveRules` can generate lots of data.

It is also possible to use `PrometheusRules` to let Prometheus pre-process your customized metrics, and only let the rating query it.
Consider this example:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: prometheus-operator
    role: alert-rules
  name: prometheus-rating.rules
  namespace: monitoring
spec:
  groups:
  - name: rating.rules
    rules:
    - expr: (sum(rate(container_memory_usage_bytes[1h])) BY (pod, namespace) + on
        (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""})
        by (pod, namespace, node) * 0)) * on () group_left() usage_memory
      record: rating:pod_memory_usage:unlabeled
```

The `expr` key is the PromQL expression, and the metric become available to be queried as `record`, here `rating:pod_memory_usage:unlabeled`.
This resource is better described in their [documentation](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/).

## *ratedmetrics.rating.alterway.fr*

Everytime a rated frames is written to the database, a `RatedMetric` is emitted.
It contains informations about the metric, for other operators or applications to bind onto:

```yaml
apiVersion: rating.alterway.fr/v1
kind: RatedMetric
metadata:
  name: rated-test-metric
  namespace: rating
spec:
  date: "2020-07-30T13:39:42Z"
  metric: test_metric
```

It only contains two keys:

- **date** represent the time of the last data write
- **metric** defines the metric to query from the API

Watching updates of this custom resource helps only querying new data from our system.
Creation of a `RatedMetric` has to be done by the rating-operator, not the user.

It is possible to delete a `RatedMetric` to trigger the reprocessing of the given metric.
In case of changes applied to an older set of rules, this is how one should act. More information on why [here](/documentation/FEATURES.md).
