# **Custom Resources**

The `rating-operator` uses *CustomResources* for most of its configuration need.
It also emits one to signify other applications of the availability of data.
We describe in this document every aspect of each resources we use, with usable examples.

### ***ratings**.charts.helm.k8s.io*

This resource describes a rating instance, and is used by the operator to deploy the needed stack.
It holds application specific parameters, such as image versions, resource limitations, or Prometheus instance location.
An example of such object can be found [here](/deploy/crds/charts.helm.k8s.io_v1alpha1_rating_cr.yaml)

The operator watch this resource and react to change to adapt the instance accordingly.
Multiple `Rating` stacks can be deployed in the same cluster, but only one rating instance is allowed per namespace, but the operator can, from its namespace, handle multiple `Rating` objects, and deploy them in their respective location.

You can experiment with your `Rating` configuration by running:
```sh
$ kubectl edit ratings.charts.helm.k8s.io rating
# Do some changes, changing port numbers for example
[...]
rating.charts.helm.k8s.io/rating edited
```
Once the changes are validated, you can see the operator reconfiguring the rating stack with the new parameters.
There is no validation made on the content of this custom resource.
Also, configuring your `Rating` is recommanded **BEFORE** you deploy your instance, even if reconfiguring is an option.

### ***ratingrules**.rating.alterway.fr*

This custom resource serves multiple purposes:
- Describing the `Metrics` list considered by this set of rules
- Describing the `Rules` used by the operator to rate metrics

`RatingRules` are used depending on the validation timestamp they hold, to enable configuration versionning.
More info on the subject [here](/documentation/FEATURES.md)


Considering this minimal example:
```yml
---
apiVersion: rating.alterway.fr/v1
kind: RatingRule
metadata:
  name: example-rules
  namespace: example-namespace
spec:
  metrics:
    request_cpu:
      report_name: pod-rating-cpu-request-hourly
      presto_table: report_metering_pod_rating_cpu_request_hourly
      presto_column: pod_request_cpu_core_seconds
      unit: core-seconds
  rules:
  -
    name: rules_example
    labelSet:
        foo: bar
    rules:
    -
        metric: request_cpu
        price: 0.00075
        unit: core-hours
  -
    name: rules_default
    rules:
    -
      metric: request_cpu
      price: 0.5
      unit: core-hours
```

The first half of this configuration -`metrics`- is used by the *scalable* rating to get data from `metering-operator`. It contains 5 points:
- The top key is the **name of the metric** in the database (here, **request_cpu**). It will also be used to match a rule in the `Rules` category.
- **report_name** is the name of the `Reports` object generated by metering-operator. A list of available reports can be obtained by using
```sh
$ kubectl -n $METERING_NAMESPACE get reports.metering.openshift.io
NAME                               QUERY                       SCHEDULE   RUNNING                  FAILED   LAST REPORT TIME       AGE
pod-rating-cpu-request-hourly      pod-rating-cpu-request      hourly     ReportingPeriodWaiting            2020-07-30T09:00:00Z   7d18h
[...]
```
- **presto_table** is the name of the table in the Presto database. It holds the aggregated data generated by metering-operator
- **presto_column** correspond to the "value" key in most databases, but changes for every reports in presto.
- **unit** will be matched with the **unit** key in `rules` defininition to apply the proper time conversion (millicore/seconds to hours for this example, GiB-hours is the other possibility).

You can have an unlimited number of metrics defined per `RatingRule`, but a metric will not be rated if it have no matches in the `rules` category.

----

The `rules` key correspond to the applied transformation to a given metric.
It is used by both rating mechanism, with some differences that are detailled [here](/documentation/FEATURES.md).

`Rules` are described as an ordered list to enable pattern matching, via the **labelSet** key.
In our example, if a data frame have a {'foo': 'bar'} label and its metric is *request_cpu*, it will be rated by the **rules_example** ruleset.
On the other hand, if the match doesn't succeed, then the operator will keep trying to match successive ruleset until:
- It finds an appropriate ruleset to match labels with
- It finds a ruleset that doesn't require labels matching and have a rule for its metric, in our case **rules_default**.

If no matches are found at the end of the list, the frame is skipped.

The latest `RatingRule` is exposed to Prometheus as a metric, to be used by the `ReactiveRules` or `PrometheusRules`.
You can expect to find each **labelSet** with their respective value plus the value of default ruleset as metric in Prometheus.
```sh
usage_cpu{[...]}
usage_cpu{[...], foo="bar"}
```


### ***reactiverules**.rating.alterway.fr*

A `ReactiveRule` describe the configuration of a metric to be processed by the *reactive* mechanism.
Let's consider this example:
```yml
apiVersion: rating.alterway.fr/v1
kind: ReactiveRule
metadata:
  name: reactive-rule-test-metric
spec:
  metric: (sum(rate(container_memory_usage_bytes[2h])) BY (pod, namespace) + on (pod,
    namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""})
    by (pod, namespace, node) * 0)) * on () group_left() usage_memory
  name: test_metric
  timeframe: 10s
```
Three keys have to be defined in a `ReactiveRule`:
- **metric** defines what to query from Prometheus. Every valid PromQL expression can be used here.
- **name** is the future name of the metric
- **timeframe** correspond to the time between every data processing run. It also defines the precision of your metric. Only values in seconds are accepted, as shown above. In case of wrong format, base value is used (60s)

As soon as this resource is created, the *reactive* mechanism will pick it up and start processing frames.
Before lowering the **timeframe** too much, verify your storage capatibilities to not overload it.
There's no mechanism yet to rotate the data in the database, and multiple `ReactiveRules` can generate lots of data.

It is also recommanded to use `PrometheusRules` to let Prometheus pre-process your customized metrics, and only let the rating query it.
Consider this example:
```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app: prometheus-operator
    role: alert-rules
  name: prometheus-rating.rules
  namespace: monitoring
spec:
  groups:
  - name: rating.rules
    rules:
    - expr: (sum(rate(container_memory_usage_bytes[1h])) BY (pod, namespace) + on
        (pod, namespace) group_left(node) (sum(kube_pod_info{pod_ip!="",node!="",host_ip!=""})
        by (pod, namespace, node) * 0)) * on () group_left() usage_memory
      record: rating:pod_memory_usage:unlabeled
```
The `expr` key is the PromQL expression, and the metric become available to be queried as record, here `rating:pod_memory_usage:unlabeled`.
This resource is better described in their [documentation](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/).

##### *ratedmetrics.rating.alterway.fr*

Everytime a rated frames is written to the database, a `RatedMetric` is emitted.
It contains informations about the metric, for other operators or applications to bind onto:
```yaml
apiVersion: rating.alterway.fr/v1
kind: RatedMetric
metadata:
  name: rated-test-metric
  namespace: rating
spec:
  date: "2020-07-30T13:39:42Z"
  metric: test_metric
```
It only contains two keys:
- **date** represent the time of the last data write
- **metric** defines the metric to query from the API

Watching updates of this custom resource helps only querying new data from our system.
Creation of a `RatedMetric` has to be done by the rating-operator, not the user.
It is possible to delete a `RatedMetric` to trigger the reprocessing of the given metric. In case of changes applied to an older set of rules, this is how one should act. More information on why [here](/documentation/FEATURES.md).
